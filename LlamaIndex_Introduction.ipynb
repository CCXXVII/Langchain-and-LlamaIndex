{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEj54t9FEk8q",
        "outputId": "8d120b53-d239-4494-b2fb-def10110abaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.5/943.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index==0.9.14.post3 openai==1.3.8 cohere==4.37"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add API Keys\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
        "\n",
        "# Enable Logging\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "#You can set the logging level to DEBUG for more verbose output,\n",
        "# or use level=logging.INFO for less detailed information.\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "bJnjoty2EoiN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import download_loader\n",
        "\n",
        "WikipediaReader = download_loader(\"WikipediaReader\")\n",
        "\n",
        "loader = WikipediaReader()\n",
        "\n",
        "documents = loader.load_data(pages=['Natural Language Processing', 'Artificial Intelligence'])\n",
        "print(len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_k0cvhmE4Ro",
        "outputId": "08e7ea6b-61ce-428a-adbf-19850fb16044"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "\n",
        "# Assuming documents have already been loaded\n",
        "\n",
        "# Initialize the parser\n",
        "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
        "\n",
        "# Parse documents into nodes\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "print(len(nodes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfvwxwf4FUcu",
        "outputId": "3a5d7780-8a83-4c2a-d7d8-af3d3f6bfe42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "from dotenv import load_dotenv\n",
        "from llama_index import download_loader\n",
        "from llama_hub.github_repo import GithubRepositoryReader, GithubClient\n",
        "from llama_index import VectorStoreIndex\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "import re\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Fetch and set API keys\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "dataset_path = os.getenv(\"DATASET_PATH\")\n",
        "\n",
        "\n",
        "def parse_github_url(url):\n",
        "    pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else (None, None)\n",
        "\n",
        "\n",
        "def validate_owner_repo(owner, repo):\n",
        "    return bool(owner) and bool(repo)\n",
        "\n",
        "\n",
        "def initialize_github_client():\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    return GithubClient(github_token)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Check for OpenAI API key\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise EnvironmentError(\"OpenAI API key not found in environment variables\")\n",
        "\n",
        "    # Check for GitHub Token\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    if not github_token:\n",
        "        raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
        "\n",
        "    # Check for Activeloop Token\n",
        "    active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "    if not active_loop_token:\n",
        "        raise EnvironmentError(\"Activeloop token not found in environment variables\")\n",
        "\n",
        "    github_client = initialize_github_client()\n",
        "    download_loader(\"GithubRepositoryReader\")\n",
        "\n",
        "    github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "    owner, repo = parse_github_url(github_url)\n",
        "\n",
        "    while True:\n",
        "        owner, repo = parse_github_url(github_url)\n",
        "        if validate_owner_repo(owner, repo):\n",
        "            loader = GithubRepositoryReader(\n",
        "                github_client,\n",
        "                owner=owner,\n",
        "                repo=repo,\n",
        "                filter_file_extensions=(\n",
        "                    [\".py\", \".js\", \".ts\", \".md\"],\n",
        "                    GithubRepositoryReader.FilterType.INCLUDE,\n",
        "                ),\n",
        "                verbose=False,\n",
        "                concurrent_requests=5,\n",
        "            )\n",
        "            print(f\"Loading {repo} repository by {owner}\")\n",
        "            docs = loader.load_data(branch=\"main\")\n",
        "            print(\"Documents uploaded:\")\n",
        "            for doc in docs:\n",
        "                print(doc.metadata)\n",
        "            break  # Exit the loop once the valid URL is processed\n",
        "        else:\n",
        "            print(\"Invalid GitHub URL. Please try again.\")\n",
        "            github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "\n",
        "    print(\"Uploading to vector store...\")\n",
        "\n",
        "    # ====== Create vector store and upload data ======\n",
        "\n",
        "    vector_store = DeepLakeVectorStore(\n",
        "        dataset_path=dataset_path,\n",
        "        overwrite=True,\n",
        "        runtime={\"tensor_db\": True},\n",
        "    )\n",
        "\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\n",
        "    query_engine = index.as_query_engine()\n",
        "\n",
        "    # Include a simple question to test.\n",
        "    intro_question = \"What is the repository about?\"\n",
        "    print(f\"Test question: {intro_question}\")\n",
        "    print(\"=\" * 50)\n",
        "    answer = query_engine.query(intro_question)\n",
        "\n",
        "    print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "    while True:\n",
        "        user_question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
        "        if user_question.lower() == \"exit\":\n",
        "            print(\"Exiting, thanks for chatting!\")\n",
        "            break\n",
        "\n",
        "        print(f\"Your question: {user_question}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        answer = query_engine.query(user_question)\n",
        "        print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "s_5XJEzVbwMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}